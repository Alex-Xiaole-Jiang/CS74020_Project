{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670ef516-7d39-4919-b2bd-c1e0802024e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f3dcc21-6781-4212-86ee-7f226580107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mteb/cqadupstack-physics\", \"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e07c889e-9154-41cc-99aa-2ff3f830cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/multi-qa-distilbert-cos-v1'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = (\n",
    "    \"output/fune_tuning_model-multi-qa-distilbert-cos-v1-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7316044c-55fc-4dbc-b5df-5605d67df89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dollcrusader\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(model_name, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "acc3d1d1-0815-427f-9be1-7c3508c967d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dollcrusader\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ori = SentenceTransformer(model_name, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff14135f-ceb4-4d2f-94ff-a7b784e1e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = dataset['corpus'].shape[0]\n",
    "train_index = int(index*0.6)\n",
    "dev_index = int(index*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f445388-46e6-4b5b-954b-9ead0697f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(index*0.1)\n",
    "train_index = int(train_index*0.1)\n",
    "dev_index = int(dev_index*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c658e6c8-5b39-46cb-9ce6-6bdf80247251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3831 2298 3065\n"
     ]
    }
   ],
   "source": [
    "print(index, train_index, dev_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f31bdced-90e6-4d89-bce8-2d1917b39497",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shuffled = dataset['corpus'].shuffle()\n",
    "train_samples = Dataset.from_dict(dataset_shuffled[0:train_index])\n",
    "dev_samples = Dataset.from_dict(dataset_shuffled[train_index:dev_index])\n",
    "test_samples = Dataset.from_dict(dataset_shuffled[dev_index:index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b603f56a-2d33-4ee9-871a-e3947676254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputData(dataset):\n",
    "    samples_set = []\n",
    "    for title, text in zip(dataset['title'], dataset['text']):\n",
    "        input = InputExample(texts=[title, text], label = 1.0)\n",
    "        samples_set.append(input)\n",
    "    return samples_set   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0340569d-3f2d-410e-8a2c-d52bfd68cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputData_tri(dataset):\n",
    "    samples_set = []\n",
    "    l = len(dataset['title'])\n",
    "    h = int(l/2)\n",
    "    for title, text in zip(dataset['title'], dataset['text']):\n",
    "        input = InputExample(texts=[title, text], label = 1.0)\n",
    "        samples_set.append(input)\n",
    "    for title, text in zip(dataset['title'][0:h], dataset['text'][h:h*2]):\n",
    "        input = InputExample(texts=[title, text], label = 0.0)\n",
    "        samples_set.append(input)\n",
    "    for title, text in zip(dataset['title'][h:h*2], dataset['text'][0:h]):\n",
    "        input = InputExample(texts=[title, text], label = 0.0)\n",
    "        samples_set.append(input)\n",
    "    return samples_set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e14f8582-b8e9-42b2-bf14-6357eb793179",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_set = InputData_tri(train_samples)\n",
    "test_samples_set = InputData_tri(test_samples)\n",
    "dev_samples_set = InputData_tri(dev_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23b9c4fc-eff2-42b7-918d-61b9d5ca4ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6346251873333523"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(test_samples.shape[0]):\n",
    "    query_emb = model.encode(test_samples['title'][i])\n",
    "    doc_emb = model.encode(test_samples['text'][i])\n",
    "    scores = scores + util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0]\n",
    "average_scores = scores/test_samples.shape[0]\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6856bfe3-e965-42ae-bc49-bc95305d774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1123767632303146"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = 0\n",
    "for i in range(test_samples.shape[0]-2):\n",
    "    query_emb = model.encode(test_samples['title'][i])\n",
    "    doc_emb = model.encode(test_samples['text'][i+2])\n",
    "    scores = scores + util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0]\n",
    "average_scores = scores/test_samples.shape[0]\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca640107-09cf-4337-94e0-f62e9678a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = 0\n",
    "for i in range(test_samples.shape[0]):\n",
    "    query_emb = model.encode(test_samples['title'][i])\n",
    "    doc_emb = model.encode(test_samples['text'][i])\n",
    "    scores = scores + util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0]\n",
    "average_scores = scores/test_samples.shape[0]\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "796a0864-cde5-479d-95aa-a37ccb7323b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "label = []\n",
    "for data in test_samples_set:\n",
    "    query_emb = model.encode(data.texts[0])\n",
    "    doc_emb = model.encode(data.texts[1])\n",
    "    scores.append(util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0])\n",
    "    label.append(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b23545c-2e4a-46ae-9cda-f3d125a1d188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947286435929074"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(label, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a5cc869d-7765-4ffd-a78c-6ae12388d281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118798955613577"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for data in test_samples_set:\n",
    "    query_emb = model_ori.encode(data.texts[0])\n",
    "    doc_emb = model_ori.encode(data.texts[1])\n",
    "    scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0]\n",
    "    label = data.label\n",
    "    i += 1\n",
    "    if scores > 0.5:\n",
    "        if label == 1.0:\n",
    "            j += 1\n",
    "    else:\n",
    "        if label == 0.0:\n",
    "            j += 1\n",
    "j/i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80e7573b-ff02-4fee-a661-1b8929106344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634464751958225"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for data in test_samples_set:\n",
    "    query_emb = model.encode(data.texts[0])\n",
    "    doc_emb = model.encode(data.texts[1])\n",
    "    scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()[0]\n",
    "    label = data.label\n",
    "    i += 1\n",
    "    if scores > 0.5:\n",
    "        if label == 1.0:\n",
    "            j += 1\n",
    "    else:\n",
    "        if label == 0.0:\n",
    "            j += 1\n",
    "j/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d661c6c8-f3f8-4a16-93ab-7d7a3632efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples_set, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a3de056-4007-4700-b49b-a041f7cec7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x15e48c4f250>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9964dfb5-0cf9-440d-b7dd-c9e117e91af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples_set, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cc6f1f62-c53e-4f94-8c42-757c82a4bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4465bb9d-2e21-48d8-930c-425af3558094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71d699b8b9046afadc132f83c9c25fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f7a0cf95f14eed820497bc52d065c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0194bbc5ab184b22ab410b89c95a0dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff696588b4b47d3ada534c6e1b880f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fd40a782aa4c94b30a1d9c422c5323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f6100ad-e2ed-4162-9a92-ff450b5e2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name output/fune_tuning_model-multi-qa-distilbert-cos-v1-2024-05-18_16-40-38. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "output/fune_tuning_model-multi-qa-distilbert-cos-v1-2024-05-18_16-40-38 does not appear to have a file named config.json. Checkout 'https://huggingface.co/output/fune_tuning_model-multi-qa-distilbert-cos-v1-2024-05-18_16-40-38/tree/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_save_path)\n\u001b[0;32m      2\u001b[0m test_evaluator \u001b[38;5;241m=\u001b[39m EmbeddingSimilarityEvaluator\u001b[38;5;241m.\u001b[39mfrom_input_examples(test_samples_set, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:205\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[0;32m    197\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[0;32m    198\u001b[0m             model_name_or_path,\n\u001b[0;32m    199\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    203\u001b[0m         )\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[0;32m    206\u001b[0m             model_name_or_path,\n\u001b[0;32m    207\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    208\u001b[0m             cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m    209\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    210\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[0;32m    214\u001b[0m     modules \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1197\u001b[0m, in \u001b[0;36mSentenceTransformer._load_auto_model\u001b[1;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;124;03mCreates a simple Transformer + Mean Pooling model and returns the modules\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo sentence-transformers model found with name \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Creating a new one with MEAN pooling.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1194\u001b[0m         model_name_or_path\n\u001b[0;32m   1195\u001b[0m     )\n\u001b[0;32m   1196\u001b[0m )\n\u001b[1;32m-> 1197\u001b[0m transformer_model \u001b[38;5;241m=\u001b[39m Transformer(\n\u001b[0;32m   1198\u001b[0m     model_name_or_path,\n\u001b[0;32m   1199\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m   1200\u001b[0m     model_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: token, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: trust_remote_code, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: revision},\n\u001b[0;32m   1201\u001b[0m     tokenizer_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: token, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: trust_remote_code, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: revision},\n\u001b[0;32m   1202\u001b[0m )\n\u001b[0;32m   1203\u001b[0m pooling_model \u001b[38;5;241m=\u001b[39m Pooling(transformer_model\u001b[38;5;241m.\u001b[39mget_word_embedding_dimension(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [transformer_model, pooling_model]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:35\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_seq_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_lower_case\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[1;32m---> 35\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     39\u001b[0m     tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path,\n\u001b[0;32m     40\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    926\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\transformers\\configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\transformers\\configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    687\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    688\u001b[0m         configuration_file,\n\u001b[0;32m    689\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    690\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    691\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    692\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    693\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    694\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    695\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    696\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    697\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    698\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    699\u001b[0m     )\n\u001b[0;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\transformers\\utils\\hub.py:369\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[1;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         )\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: output/fune_tuning_model-multi-qa-distilbert-cos-v1-2024-05-18_16-40-38 does not appear to have a file named config.json. Checkout 'https://huggingface.co/output/fune_tuning_model-multi-qa-distilbert-cos-v1-2024-05-18_16-40-38/tree/None' for available files."
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples_set, name=\"test\")\n",
    "# test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f31f1bc-9371-41a4-a6f9-f4fa84aa47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = InputExample(texts=[train_samples['title'][0], train_samples['text'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "253c47ac-fc3a-45d8-ba56-1733f6492849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is there a [set of] rules/patterns that apply to elements'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e491f54-c5bb-4db6-9502-77ce4e2726f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
