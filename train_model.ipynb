{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670ef516-7d39-4919-b2bd-c1e0802024e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd177bd1-2e45-4f1b-aeaa-81cfcb84ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"datasets/data_01.gz\"\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    util.http_get(\"http://knowitall.cs.washington.edu/oqa/data/kb/part-00000.gz\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07c889e-9154-41cc-99aa-2ff3f830cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'sentence-transformers/multi-qa-distilbert-cos-v1'\n",
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = (\n",
    "    \"output/fune_tuning_model-multi-qa-distilbert-cos-v1-\" + datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7316044c-55fc-4dbc-b5df-5605d67df89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dollcrusader\\anaconda3\\envs\\ML_Final\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c1c7dc-0a8f-4031-a6aa-5c9f67559d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['arg1', ' Ludwik Norwid ', 'rel', 'Gender', 'arg2', 'Male', 'arg1_fbid_s', '0v1jdry', 'arg2_fbid_s', '05zppz', 'id', 'fb-45251293', 'namespace', 'freebase']\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Read train dataset\")\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "with gzip.open(dataset_path, \"rt\", encoding=\"utf8\") as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    column_names = reader.fieldnames\n",
    "    print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78532557-239a-4c24-91be-7afecb1263da",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(fIn, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_NONE)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m----> 8\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5.0\u001b[39m  \u001b[38;5;66;03m# Normalize score to range 0 ... 1\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     inp_example \u001b[38;5;241m=\u001b[39m InputExample(texts\u001b[38;5;241m=\u001b[39m[row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence1\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence2\u001b[39m\u001b[38;5;124m\"\u001b[39m]], label\u001b[38;5;241m=\u001b[39mscore)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'score'"
     ]
    }
   ],
   "source": [
    "logging.info(\"Read train dataset\")\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "with gzip.open(dataset_path, \"rt\", encoding=\"utf8\") as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row[\"score\"]) / 5.0  # Normalize score to range 0 ... 1\n",
    "        inp_example = InputExample(texts=[row[\"sentence1\"], row[\"sentence2\"]], label=score)\n",
    "\n",
    "        if row[\"split\"] == \"dev\":\n",
    "            dev_samples.append(inp_example)\n",
    "        elif row[\"split\"] == \"test\":\n",
    "            test_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661c6c8-f3f8-4a16-93ab-7d7a3632efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964dfb5-0cf9-440d-b7dd-c9e117e91af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f1f62-c53e-4f94-8c42-757c82a4bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)  # 10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4465bb9d-2e21-48d8-930c-425af3558094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6100ad-e2ed-4162-9a92-ff450b5e2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=\"test\")\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
